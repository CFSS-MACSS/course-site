<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Text analysis:   topic modeling and sentiment analysis</title>
    <meta charset="utf-8" />
    <meta name="author" content="MACSS 30500   University of Chicago" />
    <script src="index_files/header-attrs/header-attrs.js"></script>
    <link href="index_files/panelset/panelset.css" rel="stylesheet" />
    <script src="index_files/panelset/panelset.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Text analysis: <br /> topic modeling and sentiment analysis
]
.author[
### MACSS 30500 <br /> University of Chicago
]

---





# Agenda
* Topic Modeling
  * LDA
* Sentiment Analysis
  * Positive / negative sentiment
* Application: TS!
* Future applications: 
    *author prediction

---
class: inverse, middle

# Topic Modeling

---

# Topic Modeling

Method to organize and understand large collections of textual information (without reading them).

How? 
--
By **finding groups of words ("topics") that go together.** Words that co-occur more frequently that chance alone would predict are assigned to the same topic.

Example: organizing 1.2M books into 2000 topics see David Mimno [slides here](https://mimno.infosci.cornell.edu/slides/details.pdf) and [video here](https://vimeo.com/53080123). 

---

# Topic Modeling

**Word Frequency** looks at the exact recurrence of each word in a corpus (using a simple count or a weighted count).

Instead: 

**Topic Modeling** looks at how groups of words co-occur together (using probability).

--

Intuition: 

The meaning of words is dependent upon the broader context in which they are used. 

---

# Topic Modeling

A topic is a set of words that are associated with one another, showing an underlying common theme that is semantically interpretable by humans. 

A topic is similar to what a human would call a theme or a discourse: whenever a specific discourse is made, some words tend to come up more frequently than others. The goal of TM is to identify the discourses that characterize a collection of documents. 

---

# Topic Modeling

One way to think about how TM…

Imagine working through an article with a set of highlighters. As you read through the article:
  * you use a different color for the key words of themes within the article as you encounter them
  * when you were done, you could take all words of the same color and create separate lists (one per each topic)


---

# Topic Modeling

&lt;img src="tm.png" width="90%" style="display: block; margin: auto;" /&gt;

---

# Topic Modeling: LDA

TM is the name of a family of algorithms. The most common is **LDA or Latent Dirichlet Allocation**. This model assumes that:

1. every document in a corpus contains a mixture of topics that are found throughout the entire corpus

1. each topic is made of a (limited) mixture of characteristic words, which tend to occur together whenever the topic is displayed

The topic structure is hidden ("latent"): we can only observe the documents and words, not the topics themselves; the goal is to infer such topics by the words and documents (more formally: topic modeling computes the conditional posterior distribution of latent variables, e.g. topics, given the observed variables, e.g. words in documents).

---

# Topic Modeling: LDA

**LDA works as follows:**

1. The researcher begins by setting an arbitrary number of topics (`k`) for the whole collection of documents.

1. The algorithm (Gibbs sampling) creates, simultaneously:
    * a first randomly chosen word-topic probability: distribution of topics over all observed words in the collection
    * a first randomly chosen document-topic probability: distribution of topics by document 

1. Through reiterative attempts, the algorithm adjusts these initial distributions to provide a set of probabilities for every word-topic pair and for every document-topic pair. 

---

# Topic Modeling: LDA

**LDA produces two types of output:**

1. words most frequently associated with each of the `k` topics specified by the researcher 

1. documents most frequently associated with each of the `k` topics (the researcher defines a probabilty theresold)

---

# Topic Modeling: LDA simple example

We start with a simple example, then move to a real example in R. Imagine we have a corpus with the following five documents (each document is one sentence):

**Document 1**  I ate a banana and spinach smoothie for breakfast.

**Document 2**  I like to eat broccoli and bananas.

**Document 3**  Puppies and kittens are cute.

**Document 4**  My sister adopted a kitten yesterday.

**Document 5**  This cute hamster is eating a piece of broccoli.

---

# Topic Modeling: LDA simple example

**First, we need to transform these textual data in the appropriate form needed for LDA:**
* input:
  * raw data
* output:
  * create a vocabulary (remove stop words, lowercase, tokenize, etc.)
  * create a document-term matrix

**Then, we run LDA:**
* input:
  * the document-term matrix as input
  * the number of topics we want to generate (we decide them)
* output:
  * the word-topic and document-topic probabilities

---

# Topic Modeling: LDA simple example

If we give to LDA the document-term matrix from these 5 documents, and we ask for 2 topics, LDA might produce something like: 

**Topic A:** 30% eat, 20% broccoli, 15% bananas, 10% breakfast, …

**Topic B:** 20% dog, 20% kitten, 20% cute, 15% hamster, …

--

**Document 1 and 2** 100% Topic A (we can label it "food")

**Document 3 and 4**: 100% Topic B (we can label it "cute animals")

**Document 5:** 60% Topic A, 40% Topic B

---

# Topic Modeling: LDA example in R

Download today's class materials to access the code. () We have additional resources you can practice with as well!

**Examples from the book**: Chapter 6, and the three case-study chapters + Chapter 2 to reshape the data into the appropriate format for LDA


---
class: inverse, middle, center

![](https://media.giphy.com/media/tNTq5fw9apN2OzZID9/giphy.gif) 

---
# A thorough examination of Taylor Swift Lyrics   
--
Recall the following graphic:  
![visualization of textual analysis process](https://www.tidytextmining.com/images/tmwr_0101.png)  
--

We will move through this process using [this dataset of Taylor Swift albums and lyrics from Kaggle](https://www.kaggle.com/datasets/ishikajohari/taylor-swift-all-lyrics-30-albums?resource=download)

---
## Basic workflow for text analysis

We can think at the basic workflow as a 4-step process:

1. Obtain your textual data: **Kaggle, check!**

1. Data cleaning and pre-processing **OOF THIS WAS A PAIN** *see end of slides for more detail*

1. Data transformation **building on last class's materials**

1. Perform analysis **the fun part**


---
# Steps: Data cleaning and pre-processing    
Without belaboring this too much, you can see in today's files where I have the raw data I imported and cleaned, and how I timmed out unwanted characteristics / elements, e.g. [Chorus]. 

Here is a snippet of what the raw structure was: `data &gt; albums &gt; 1989 &gt; song.txt`    

Here is what the raw txt file looked like: 

```r
read_file(here("..", "text-analysis-fundamentals-and-sentiment-analysis-and-tm", "data", "swift_data_raw", "Albums", "1989", "BlankSpace.txt"))
## [1] "237 ContributorsTranslationsTürkçeEspañolPortuguêsPolskiΕλληνικάFrançaisBlank Space Lyrics[Verse 1]\nNice to meet you, where you been?\nI could show you incredible things\nMagic, madness, heaven, sin\nSaw you there and I thought\n\"Oh, my God, look at that face\nYou look like my next mistake\nLove's a game, wanna play?\" Ayy\nNew money, suit and tie\nI can read you like a magazine\nAin't it funny? Rumors fly\nAnd I know you heard about me\nSo, hey, let's be friends\nI'm dying to see how this one ends\nGrab your passport and my hand\nI can make the bad guys good for a weekend\n[Chorus]\nSo, it's gonna be forever\nOr it's gonna go down in flames?\nYou can tell me when it's over, mm\nIf the high was worth the pain\nGot a long list of ex-lovers\nThey'll tell you I'm insane\n'Cause you know I love the players\nAnd you love the game\n'Cause we're young and we're reckless\nWe'll take this way too far\nIt'll leave you breathless, mm\nOr with a nasty scar\nGot a long list of ex-lovers\nThey'll tell you I'm insane\nBut I've got a blank space, baby\nAnd I'll write your name\n\n[Verse 2]\nCherry lips, crystal skies\nI could show you incredible things\nStolen kisses, pretty lies\nYou're the king, baby, I'm your queen\nFind out what you want\nBe that girl for a month\nWait, the worst is yet to come, oh, no\nScreaming, crying, perfect storms\nI can make all the tables turn\nRose garden filled with thorns\nKeep you second guessing, like\n\"Oh, my God, who is she?\"\nI get drunk on jealousy\nBut you'll come back each time you leave\n'Cause, darling, I'm a nightmare dressed like a daydream\nYou might also like[Chorus]\nSo, it's gonna be forever\nOr it's gonna go down in flames?\nYou can tell me when it's over, mm\nIf the high was worth the pain\nGot a long list of ex-lovers\nThey'll tell you I'm insane\n'Cause you know I love the players\nAnd you love the game\n'Cause we're young and we're reckless (Oh)\nWe'll take this way too far\nIt'll leave you breathless (Oh-oh), mm\nOr with a nasty scar\nGot a long list of ex-lovers\nThey'll tell you I'm insane (Insane)\nBut I've got a blank space, baby\nAnd I'll write your name\n\n[Bridge]\nBoys only want love if it's torture\nDon't say I didn't, say I didn't warn ya\nBoys only want love if it's torture\nDon't say I didn't, say I didn't warn ya\n\n[Chorus]\nSo, it's gonna be forever\nOr it's gonna go down in flames?\nYou can tell me when it's over (Over), mm\nIf the high was worth the pain\nGot a long list of ex-lovers\nThey'll tell you I'm insane (I'm insane)\n'Cause you know I love the players\nAnd you love the game (And you love the game)\n'Cause we're young and we're reckless (Yeah)\nWe'll take this way too far (Ooh)\nIt'll leave you breathless, mm\nOr with a nasty scar (With a nasty scar)\nGot a long list of ex-lovers\nThey'll tell you I'm insane\nBut I've got a blank space, baby\nAnd I'll write your name1KEmbed"
```

---
# Steps:

--
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="../../img/ts_frequent_words.png" alt="Histogram of text containing stop words" width="40%" /&gt;
&lt;p class="caption"&gt;Histogram of text containing stop words&lt;/p&gt;
&lt;/div&gt;

---
# Steps:

--
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="../../img/ts_frequent_words.png" alt="Histogram of text containing stop words" width="40%" /&gt;
&lt;p class="caption"&gt;Histogram of text containing stop words&lt;/p&gt;
&lt;/div&gt;
---
# Steps:

--
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="../../img/ts_negative_words_album.png" alt="Histogram of text containing stop words" width="40%" /&gt;
&lt;p class="caption"&gt;Histogram of text containing stop words&lt;/p&gt;
&lt;/div&gt;

---
# Steps:

--
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="../../img/ts_positive_words_album.png" alt="Histogram of text containing stop words" width="40%" /&gt;
&lt;p class="caption"&gt;Histogram of text containing stop words&lt;/p&gt;
&lt;/div&gt;

---
# Steps: Visualizations (Wordcloud)

--
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="../../img/ts_wordcloud.png" alt="Histogram of text containing stop words" width="40%" /&gt;
&lt;p class="caption"&gt;Histogram of text containing stop words&lt;/p&gt;
&lt;/div&gt;


---
# Steps: Visualizations

--
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="../../img/ts_sentiment_album.png" alt="Histogram of text containing stop words" width="40%" /&gt;
&lt;p class="caption"&gt;Histogram of text containing stop words&lt;/p&gt;
&lt;/div&gt;
---
class: inverse, middle, center

![](https://media.giphy.com/media/ej1WNA2G75DfUai7NR/giphy.gif)

---

# Topic modeling: pros/cons

* Topic models **account for "multiplexity":** a given document is unlikely to fall precisely and fully into a single topic 

* Topic models **do not care about the order of words** “dog eats food" is the same as "food eats dog" 

* To determine the "right" number of topics: no fixed rule, it is a try-error process, ultimately **the researcher decides** (there are some metrics, such as perplexity and coherence score but are beyond our goals)

* Topics are **unlabeled:** they are just a bunch of words, it is up to the researcher to read, interpret, and label them

* Topic models are **no substitute for human interpretation of a text:** they are a way of making educated guesses about how words cohere into different latent themes by identifying patterns in the way they co-occur within documents. Many people are somewhat disappointed when they discover their model produces uninformative results

---

# LDAvis

LDAvis is a an interactive visualization of LDA model results

https://github.com/cpsievert/LDAvis


1. What is the meaning of each topic?
1. How prevalent is each topic?
1. How do the topics relate to each other?

---

class: inverse, middle

# Sentiment Analysis

---

# Sentiment Analysis

Use of NLP and programming to **study emotional states and subjective information in a text**. 

In practice sentiment analysis is usually applied:
* to determine the polarity of a text: whether a text is positive, negative, or neutral
* to detect specific feelings and emotions: angry, sad, happy, etc.
* examples: analyzing costumer feedback, classify movies review

Different from Topic Modeling, Sentiment Analysis it is usually supervised (e.g., needs a labeled input to compare our text to)

---

# Sentiment Analysis: our approach

Our approach to sentiment analysis (consistent with the book, Chapter 2): 

* consider the text a combination of its individual words, and 
* consider the sentiment content of the text as the sum of the sentiment content of the individual words

Notice: "This isn’t the only way to approach sentiment analysis, but it is an often-used approach, and an approach that naturally takes advantage of the tidy tool ecosystem."

---

# The `sentiments` datasets 

The tidytext package provides access to several sentiment lexicons:

+ **AFINN** from Finn Årup Nielsen (words classified with on a scale from -5 to +5)
+ **bing** from Bing Liu and collaborators (words classified into binary categories: negative and positive)
+ **nrc** from Saif Mohammad and Peter Turney (words classified in multiple categories)

See: https://www.tidytextmining.com/sentiment.html#the-sentiments-datasets

---

# The `sentiments` datasets

These dictionaries constitute our gold standard (e.g., our labeled sentiments): we use them to classify our texts.

Dictionary-based methods like these find the total sentiment of a piece of text by adding up the individual sentiment scores for each word in the text.

---

# Sentiment Analysis: Examples

**Examples from the book**: Chapter 2, and the three case-study chapters

**Another example (in today's class-materials)**: sentiment analysis of Harry Potter textual data. 

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
